{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.748587180388808\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "\n",
    "X_test = test  # No need to drop 'smoking' column for test data\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train = cross_val_predict(logistic_model, X_train_scaled, y_train, cv=cv)  # Predict on training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test = logistic_model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking'] = y_pred_proba_test\n",
    "submission.to_csv('Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hada 0.78 private but takes time\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "\n",
    "X_test = test.drop(columns=['smoking'], errors='ignore')  # In case 'smoking' column is present\n",
    "\n",
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # or median, most_frequent\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using Random Forest Classifier\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train = cross_val_predict(random_forest_model, X_train_scaled, y_train, cv=cv)  # Predict on training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Accuracy on Training Data: {accuracy_train}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test = random_forest_model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = pd.DataFrame({'id': test['id'], 'smoking': y_pred_proba_test})\n",
    "submission.to_csv('Yagas_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Training Data:\n",
      "Accuracy: 0.7486185763801678\n",
      "ROC AUC: 0.747059415162687\n",
      "F1 Score: 0.7188031186345439\n",
      "Precision: 0.7036593918891043\n",
      "Recall: 0.734613010207744\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "\n",
    "X_test = test  # No need to drop 'smoking' column for test data\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using Logistic Regression with increased max_iter\n",
    "logistic_model = LogisticRegression(max_iter=1000)  # Increased max_iter\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(logistic_model, param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train = cross_val_predict(best_model, X_train_scaled, y_train, cv=cv)  # Predict on training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Classification Report on Training Data:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "print(f\"F1 Score: {f1_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test = best_model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking'] = y_pred_proba_test\n",
    "submission.to_csv('Yaga\\'s_submission1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.768630381272919\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using a more efficient Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, max_features='sqrt', random_state=42)\n",
    "\n",
    "# Efficient cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train_rf = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_rf = accuracy_score(y_train, y_pred_train_rf)\n",
    "\n",
    "print(\"Random Forest Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_rf}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_rf = test[['id']].copy()\n",
    "submission_rf['smoking'] = y_pred_proba_test_rf\n",
    "submission_rf.to_csv('Efficient_RF_Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7485055508112725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using Logistic Regression with parameter tuning\n",
    "logistic_model = LogisticRegression(C=0.5, penalty='l2', solver='liblinear', random_state=42)\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train = cross_val_predict(logistic_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Logistic Regression Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test = logistic_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking'] = y_pred_proba_test\n",
    "submission.to_csv('Logistic_Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\houss\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\houss\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7783003466117446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train_xgb = cross_val_predict(xgb_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_xgb = accuracy_score(y_train, y_pred_train_xgb)\n",
    "\n",
    "print(\"XGBoost Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_xgb}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_xgb = test[['id']].copy()\n",
    "submission_xgb['smoking'] = y_pred_proba_test_xgb\n",
    "submission_xgb.to_csv('XGBoost_Yaga\\'sTest_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7783003466117446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#best pub scoer for now\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using XGBoost Classifier\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train_xgb = cross_val_predict(xgb_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_xgb = accuracy_score(y_train, y_pred_train_xgb)\n",
    "\n",
    "print(\"XGBoost Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_xgb}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_xgb = test[['id']].copy()\n",
    "submission_xgb['smoking'] = y_pred_proba_test_xgb\n",
    "submission_xgb.to_csv('XGB2.0_Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7807555131360828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using LightGBM Classifier with suppressed logs\n",
    "lgbm_model = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train_lgbm = cross_val_predict(lgbm_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_lgbm = accuracy_score(y_train, y_pred_train_lgbm)\n",
    "\n",
    "print(\"LightGBM Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_lgbm}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "lgbm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test_lgbm = lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_lgbm = test[['id']].copy()\n",
    "submission_lgbm['smoking'] = y_pred_proba_test_lgbm\n",
    "submission_lgbm.to_csv('LGBM_Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7829029989450947\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LightGBM Classifier with suppressed logs and forced column-wise computation\n",
    "lgbm_model = LGBMClassifier(random_state=42, verbose=-1, force_col_wise=True)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(lgbm_model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lgbm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train_lgbm = cross_val_predict(best_lgbm_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_lgbm = accuracy_score(y_train, y_pred_train_lgbm)\n",
    "\n",
    "print(\"LightGBM Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_lgbm}\")\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "best_lgbm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_proba_test_lgbm = best_lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_lgbm = test[['id']].copy()\n",
    "submission_lgbm['smoking'] = y_pred_proba_test_lgbm\n",
    "submission_lgbm.to_csv('Optimized_LGBM_Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7840081378409605\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Load and preprocess data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X_train = train.drop(columns=['smoking'])\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LightGBM with extended hyperparameter tuning\n",
    "lgbm_model = LGBMClassifier(random_state=42, verbose=-1, force_col_wise=True)\n",
    "\n",
    "# Define a search space for hyperparameters\n",
    "param_distributions = {\n",
    "    'num_leaves': randint(20, 60),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0.0, 1.0),\n",
    "    'reg_lambda': uniform(0.0, 1.0)\n",
    "}\n",
    "\n",
    "# Random search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(lgbm_model, param_distributions, n_iter=100, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lgbm_model = random_search.best_estimator_\n",
    "\n",
    "# Model evaluation\n",
    "y_pred_train_lgbm = cross_val_predict(best_lgbm_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_lgbm = accuracy_score(y_train, y_pred_train_lgbm)\n",
    "print(\"LightGBM Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_lgbm}\")\n",
    "\n",
    "# Train the final model and predict\n",
    "best_lgbm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_proba_test_lgbm = best_lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions\n",
    "submission_lgbm = test[['id']].copy()\n",
    "submission_lgbm['smoking'] = y_pred_proba_test_lgbm\n",
    "submission_lgbm.to_csv('Enhanced_LGBM_Yaga\\'s_submission.csv', index=False)\n",
    "\n",
    "#hada 0.1 changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated LightGBM Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7845293112975336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Feature Engineering (Placeholder - adapt based on your dataset and domain knowledge)\n",
    "# Example: X_train['new_feature'] = X_train['feature1'] / X_train['feature2']\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LightGBM Classifier with extended hyperparameter tuning\n",
    "lgbm_model = LGBMClassifier(random_state=42, verbose=-1, force_col_wise=True)\n",
    "\n",
    "# Define a search space for hyperparameters\n",
    "param_distributions = {\n",
    "    'num_leaves': randint(20, 60),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0.0, 1.0),\n",
    "    'reg_lambda': uniform(0.0, 1.0)\n",
    "}\n",
    "\n",
    "# Random search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(lgbm_model, param_distributions, n_iter=100, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model from random search\n",
    "best_lgbm_model = random_search.best_estimator_\n",
    "\n",
    "# Adjusting model complexity (Example - adjust as needed)\n",
    "best_lgbm_model.set_params(max_depth=8, min_child_samples=20)\n",
    "\n",
    "# Re-train the model with the updated complexity\n",
    "best_lgbm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Re-evaluate the model\n",
    "y_pred_train_lgbm = cross_val_predict(best_lgbm_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_lgbm = accuracy_score(y_train, y_pred_train_lgbm)\n",
    "print(\"Updated LightGBM Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_lgbm}\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_proba_test_lgbm = best_lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_lgbm = test[['id']].copy()\n",
    "submission_lgbm['smoking'] = y_pred_proba_test_lgbm\n",
    "submission_lgbm.to_csv('Enhanced_LGBM_Yaga\\'s_submission.csv', index=False)\n",
    "\n",
    "\n",
    "#Best Public Score (last day subs) !!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated LightGBM Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7854209574521525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80     89603\n",
      "           1       0.73      0.81      0.77     69653\n",
      "\n",
      "    accuracy                           0.79    159256\n",
      "   macro avg       0.78      0.79      0.78    159256\n",
      "weighted avg       0.79      0.79      0.79    159256\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68498 21105]\n",
      " [13068 56585]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import randint, uniform\n",
    "import numpy as np\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Feature Engineering (Placeholder - adapt based on your dataset and domain knowledge)\n",
    "# Example: X_train['new_feature'] = X_train['feature1'] / X_train['feature2']\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LightGBM Classifier with extended hyperparameter tuning\n",
    "lgbm_model = LGBMClassifier(random_state=42, verbose=-1, force_col_wise=True)\n",
    "\n",
    "# Define a search space for hyperparameters\n",
    "param_distributions = {\n",
    "    'num_leaves': randint(20, 100),  # Increased range\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(200, 1000),  # Increased range\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0.0, 1.0),\n",
    "    'reg_lambda': uniform(0.0, 1.0)\n",
    "}\n",
    "\n",
    "# Random search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Increased number of splits\n",
    "random_search = RandomizedSearchCV(lgbm_model, param_distributions, n_iter=100, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model from random search\n",
    "best_lgbm_model = random_search.best_estimator_\n",
    "\n",
    "# Re-train the model with the updated complexity\n",
    "best_lgbm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Re-evaluate the model\n",
    "y_pred_train_lgbm = cross_val_predict(best_lgbm_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_lgbm = accuracy_score(y_train, y_pred_train_lgbm)\n",
    "print(\"Updated LightGBM Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_lgbm}\")\n",
    "print(classification_report(y_train, y_pred_train_lgbm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_pred_train_lgbm))\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test_lgbm = best_lgbm_model.predict(X_test_scaled)\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_lgbm = test[['id']].copy()\n",
    "submission_lgbm['smoking'] = y_pred_test_lgbm\n",
    "submission_lgbm.to_csv('Yaga2.0\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Best Accuracy: 0.7836690502350644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(XGBClassifier(eval_metric='logloss', random_state=42), param_grid, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "xgb_model = XGBClassifier(**best_params, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_xgb = test[['id']].copy()\n",
    "submission_xgb['smoking'] = y_pred_proba_test_xgb\n",
    "submission_xgb.to_csv('XGB2.1_Yaga\\'s_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report on Training Data:\n",
      "Accuracy on Training Data: 0.7825702014366805\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking'])  # Exclude the target variable\n",
    "y_train = train['smoking']\n",
    "X_test = test\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training using XGBoost Classifier with hyperparameter tuning\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation to evaluate the model\n",
    "y_pred_train_xgb = cross_val_predict(best_xgb_model, X_train_scaled, y_train, cv=cv)\n",
    "accuracy_train_xgb = accuracy_score(y_train, y_pred_train_xgb)\n",
    "\n",
    "print(\"XGBoost Classification Report on Training Data:\")\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_xgb}\")\n",
    "\n",
    "# Train the final model on the entire training dataset using the best hyperparameters\n",
    "best_xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict smoking probabilities on the test data\n",
    "y_pred_proba_test_xgb = best_xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission_xgb = test[['id']].copy()\n",
    "submission_xgb['smoking'] = y_pred_proba_test_xgb\n",
    "submission_xgb.to_csv('XGB2.2_Yaga\\'s_submission.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report on Training Data:\n",
      "Accuracy: 0.7880428110665938\n",
      "Precision: 0.773067278902208\n",
      "Recall: 0.815463767954198\n",
      "F1 Score: 0.7936997610254183\n",
      "ROC-AUC: 0.7880428110665937\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Feature Engineering (example: BMI)\n",
    "train['bmi'] = train['weight(kg)'] / (train['height(cm)'] / 100) ** 2\n",
    "test['bmi'] = test['weight(kg)'] / (test['height(cm)'] / 100) ** 2\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking', 'id'])  # Exclude the target variable and 'id'\n",
    "y_train = train['smoking']\n",
    "X_test = test.drop(columns=['id'])  # Assuming 'id' is not a feature\n",
    "\n",
    "# Ensure X_train and X_test have the same columns\n",
    "assert X_train.columns.equals(X_test.columns), \"Columns of X_train and X_test do not match\"\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Model training using XGBoost Classifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Feature Selection\n",
    "selector = RFECV(xgb_model, step=1, cv=3)\n",
    "X_train_selected = selector.fit_transform(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_dist = {\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=50, scoring='roc_auc', cv=3, random_state=42)\n",
    "random_search.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "# Best model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred_train = cross_val_predict(best_xgb_model, X_train_selected, y_train_balanced, cv=3)\n",
    "accuracy = accuracy_score(y_train_balanced, y_pred_train)\n",
    "precision = precision_score(y_train_balanced, y_pred_train)\n",
    "recall = recall_score(y_train_balanced, y_pred_train)\n",
    "f1 = f1_score(y_train_balanced, y_pred_train)\n",
    "roc_auc = roc_auc_score(y_train_balanced, y_pred_train)\n",
    "\n",
    "print(\"XGBoost Classification Report on Training Data:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "\n",
    "# Predictions on test data\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "y_pred_proba_test = best_xgb_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking_probability'] = y_pred_proba_test\n",
    "submission.to_csv('XGB2.2_Enhanced_Submission.csv', index=False)\n",
    "\n",
    "\n",
    "# version 2 of 0.87 but runtime over \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validation Accuracy: 0.78 (+/- 0.00)\n",
      "Random Forest Cross-Validation Accuracy: 0.77 (+/- 0.00)\n",
      "Ensemble Model Accuracy on Validation Data: 0.7764661559713676\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X = train.drop(columns=['smoking'])  # Features\n",
    "y = train['smoking']  # Target variable\n",
    "\n",
    "# Feature engineering\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(poly.transform(test))\n",
    "\n",
    "# Model 1: XGBoost with cross-validation\n",
    "xgb_model = XGBClassifier(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train_scaled, y_train, cv=kfold, scoring='accuracy')\n",
    "print(\"XGBoost Cross-Validation Accuracy: %0.4f (+/- %0.4f)\" % (xgb_cv_scores.mean(), xgb_cv_scores.std() * 2))\n",
    "\n",
    "# Model 2: Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=kfold, scoring='accuracy')\n",
    "print(\"Random Forest Cross-Validation Accuracy: %0.2f (+/- %0.2f)\" % (rf_cv_scores.mean(), rf_cv_scores.std() * 2))\n",
    "\n",
    "# Model Ensembling: Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model)], voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "ensemble_accuracy = voting_clf.score(X_val_scaled, y_val)\n",
    "print(\"Ensemble Model Accuracy on Validation Data:\", ensemble_accuracy)\n",
    "\n",
    "# Final predictions on the test data using the ensemble model\n",
    "y_pred_test = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking'] = y_pred_test\n",
    "submission.to_csv('ensemble_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-02 16:49:35,593] A new study created in memory with name: no-name-c00058e2-4bd2-46d8-be51-1c2b888b4939\n",
      "[I 2024-01-02 16:51:15,186] Trial 0 finished with value: 0.8952745248781364 and parameters: {'n_estimators': 224, 'max_depth': 7, 'learning_rate': 0.08503465697761481, 'subsample': 0.9523206618913249}. Best is trial 0 with value: 0.8952745248781364.\n",
      "[I 2024-01-02 16:51:56,923] Trial 1 finished with value: 0.8683512154327626 and parameters: {'n_estimators': 133, 'max_depth': 5, 'learning_rate': 0.023010350610988533, 'subsample': 0.8340226746450462}. Best is trial 0 with value: 0.8952745248781364.\n",
      "[I 2024-01-02 16:54:46,043] Trial 2 finished with value: 0.8931251235392723 and parameters: {'n_estimators': 332, 'max_depth': 8, 'learning_rate': 0.03051641826821396, 'subsample': 0.9706018476942448}. Best is trial 0 with value: 0.8952745248781364.\n",
      "[I 2024-01-02 16:55:54,878] Trial 3 finished with value: 0.8768769197814285 and parameters: {'n_estimators': 126, 'max_depth': 8, 'learning_rate': 0.019990274014960244, 'subsample': 0.7990761120143164}. Best is trial 0 with value: 0.8952745248781364.\n",
      "[I 2024-01-02 16:57:28,998] Trial 4 finished with value: 0.8834023455724527 and parameters: {'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.02421279424523928, 'subsample': 0.8979373267704585}. Best is trial 0 with value: 0.8952745248781364.\n",
      "[I 2024-01-02 16:59:23,721] Trial 5 finished with value: 0.8952995197682831 and parameters: {'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.06348971976503702, 'subsample': 0.7320379327285573}. Best is trial 5 with value: 0.8952995197682831.\n",
      "[I 2024-01-02 17:00:37,400] Trial 6 finished with value: 0.882897916946136 and parameters: {'n_estimators': 275, 'max_depth': 4, 'learning_rate': 0.03674332419944935, 'subsample': 0.7573382956643921}. Best is trial 5 with value: 0.8952995197682831.\n",
      "[I 2024-01-02 17:01:03,324] Trial 7 finished with value: 0.8706899196613638 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.06458320505674348, 'subsample': 0.8125257379388882}. Best is trial 5 with value: 0.8952995197682831.\n",
      "[I 2024-01-02 17:02:23,609] Trial 8 finished with value: 0.8941268230438044 and parameters: {'n_estimators': 144, 'max_depth': 8, 'learning_rate': 0.08349364468546723, 'subsample': 0.8270149767189788}. Best is trial 5 with value: 0.8952995197682831.\n",
      "[I 2024-01-02 17:04:11,610] Trial 9 finished with value: 0.8917073216346548 and parameters: {'n_estimators': 234, 'max_depth': 7, 'learning_rate': 0.044110678739793546, 'subsample': 0.9919927418877396}. Best is trial 5 with value: 0.8952995197682831.\n",
      "[I 2024-01-02 17:09:14,966] Trial 10 finished with value: 0.8968158242064697 and parameters: {'n_estimators': 376, 'max_depth': 9, 'learning_rate': 0.0670008803307684, 'subsample': 0.7067446508094029}. Best is trial 10 with value: 0.8968158242064697.\n",
      "[I 2024-01-02 17:13:10,291] Trial 11 finished with value: 0.8972028932776202 and parameters: {'n_estimators': 393, 'max_depth': 9, 'learning_rate': 0.06377180252391727, 'subsample': 0.7143993227295548}. Best is trial 11 with value: 0.8972028932776202.\n",
      "[I 2024-01-02 17:17:14,957] Trial 12 finished with value: 0.8953968348936971 and parameters: {'n_estimators': 399, 'max_depth': 9, 'learning_rate': 0.0988562355269397, 'subsample': 0.7006228292853598}. Best is trial 11 with value: 0.8972028932776202.\n",
      "[I 2024-01-02 17:21:09,803] Trial 13 finished with value: 0.8973706805609561 and parameters: {'n_estimators': 399, 'max_depth': 9, 'learning_rate': 0.052924629707813135, 'subsample': 0.7617531368225252}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:24:29,098] Trial 14 finished with value: 0.8966196676035875 and parameters: {'n_estimators': 332, 'max_depth': 9, 'learning_rate': 0.05260755225408171, 'subsample': 0.7622137817518073}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:26:35,803] Trial 15 finished with value: 0.8944868080439038 and parameters: {'n_estimators': 344, 'max_depth': 6, 'learning_rate': 0.051870743686866075, 'subsample': 0.8832373628267608}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:27:09,707] Trial 16 finished with value: 0.8843949030401512 and parameters: {'n_estimators': 51, 'max_depth': 9, 'learning_rate': 0.07691670332418385, 'subsample': 0.769051809023123}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:29:54,522] Trial 17 finished with value: 0.8805203191955855 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.010910142016337492, 'subsample': 0.7367374217908649}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:31:51,437] Trial 18 finished with value: 0.8926671353961269 and parameters: {'n_estimators': 374, 'max_depth': 5, 'learning_rate': 0.0461883242432256, 'subsample': 0.7855875789926772}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:34:08,097] Trial 19 finished with value: 0.8964702264550297 and parameters: {'n_estimators': 311, 'max_depth': 7, 'learning_rate': 0.07196470262541067, 'subsample': 0.8702605430292563}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:36:03,651] Trial 20 finished with value: 0.8944288630336177 and parameters: {'n_estimators': 187, 'max_depth': 9, 'learning_rate': 0.058416737596092755, 'subsample': 0.7298099791250255}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:39:58,824] Trial 21 finished with value: 0.8970367207302662 and parameters: {'n_estimators': 399, 'max_depth': 9, 'learning_rate': 0.06664151516347877, 'subsample': 0.7030870828874841}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:43:19,957] Trial 22 finished with value: 0.8972549057028021 and parameters: {'n_estimators': 395, 'max_depth': 8, 'learning_rate': 0.07626792871981877, 'subsample': 0.7026746992362914}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:46:26,064] Trial 23 finished with value: 0.8968408028006831 and parameters: {'n_estimators': 362, 'max_depth': 8, 'learning_rate': 0.08988426144812584, 'subsample': 0.7350541741665094}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:49:50,871] Trial 24 finished with value: 0.897296912645696 and parameters: {'n_estimators': 399, 'max_depth': 8, 'learning_rate': 0.07856488906977824, 'subsample': 0.7786556860647718}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:52:58,925] Trial 25 finished with value: 0.8972123689786308 and parameters: {'n_estimators': 361, 'max_depth': 8, 'learning_rate': 0.0777448190799944, 'subsample': 0.7803820168078688}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:55:07,790] Trial 26 finished with value: 0.8970430181087259 and parameters: {'n_estimators': 297, 'max_depth': 7, 'learning_rate': 0.09710106027329958, 'subsample': 0.852150207965953}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 17:58:06,789] Trial 27 finished with value: 0.8973372974272891 and parameters: {'n_estimators': 351, 'max_depth': 8, 'learning_rate': 0.07491907293058488, 'subsample': 0.8015664547160024}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 18:00:10,196] Trial 28 finished with value: 0.8967559061063659 and parameters: {'n_estimators': 343, 'max_depth': 6, 'learning_rate': 0.0897048418885606, 'subsample': 0.8026106296164109}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 18:02:28,806] Trial 29 finished with value: 0.8955806144669223 and parameters: {'n_estimators': 318, 'max_depth': 7, 'learning_rate': 0.05731679778923114, 'subsample': 0.9152438469436417}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 18:03:28,191] Trial 30 finished with value: 0.8920981037722523 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.08326849188662519, 'subsample': 0.8474557233199872}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 18:06:37,908] Trial 31 finished with value: 0.897329917135208 and parameters: {'n_estimators': 379, 'max_depth': 8, 'learning_rate': 0.07310280273512222, 'subsample': 0.7527100205132015}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 18:09:43,628] Trial 32 finished with value: 0.8972447246369384 and parameters: {'n_estimators': 364, 'max_depth': 8, 'learning_rate': 0.07157462697438445, 'subsample': 0.7495827967908968}. Best is trial 13 with value: 0.8973706805609561.\n",
      "[I 2024-01-02 18:12:31,492] Trial 33 finished with value: 0.8973770242385077 and parameters: {'n_estimators': 376, 'max_depth': 7, 'learning_rate': 0.09091254965223243, 'subsample': 0.7933497073205825}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 18:14:51,609] Trial 34 finished with value: 0.897231934610496 and parameters: {'n_estimators': 348, 'max_depth': 7, 'learning_rate': 0.09228943215758248, 'subsample': 0.8184733826843639}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 18:18:11,930] Trial 35 finished with value: 0.8957674819950607 and parameters: {'n_estimators': 378, 'max_depth': 7, 'learning_rate': 0.045815175458734286, 'subsample': 0.79631952259286}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 18:42:04,317] Trial 36 finished with value: 0.8969628346466945 and parameters: {'n_estimators': 325, 'max_depth': 8, 'learning_rate': 0.08497531152461668, 'subsample': 0.7944545776387669}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 18:44:32,532] Trial 37 finished with value: 0.8908266308473621 and parameters: {'n_estimators': 275, 'max_depth': 6, 'learning_rate': 0.03910752625835108, 'subsample': 0.8415939501308282}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 18:48:48,536] Trial 38 finished with value: 0.8972388595691667 and parameters: {'n_estimators': 351, 'max_depth': 8, 'learning_rate': 0.07031602192034059, 'subsample': 0.7501774741137066}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:05:02,086] Trial 39 finished with value: 0.8971238580840216 and parameters: {'n_estimators': 376, 'max_depth': 9, 'learning_rate': 0.06011416628185749, 'subsample': 0.8171757816438391}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:06:30,487] Trial 40 finished with value: 0.874440794434016 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.030851320297538117, 'subsample': 0.7711027539871913}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:11:13,280] Trial 41 finished with value: 0.8973756824952857 and parameters: {'n_estimators': 381, 'max_depth': 8, 'learning_rate': 0.08119889558564465, 'subsample': 0.7760340187391463}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:15:14,598] Trial 42 finished with value: 0.8972425870095027 and parameters: {'n_estimators': 382, 'max_depth': 7, 'learning_rate': 0.09274383448756755, 'subsample': 0.7550422530335709}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:19:36,055] Trial 43 finished with value: 0.8971785592123659 and parameters: {'n_estimators': 364, 'max_depth': 8, 'learning_rate': 0.0829784343470961, 'subsample': 0.8041233491717202}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:23:38,821] Trial 44 finished with value: 0.8965037069730682 and parameters: {'n_estimators': 334, 'max_depth': 8, 'learning_rate': 0.08742998226438302, 'subsample': 0.7230193596030331}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:28:56,194] Trial 45 finished with value: 0.8971418448364379 and parameters: {'n_estimators': 380, 'max_depth': 9, 'learning_rate': 0.0726613416480698, 'subsample': 0.8269567469761465}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:31:50,729] Trial 46 finished with value: 0.8966535137069227 and parameters: {'n_estimators': 280, 'max_depth': 7, 'learning_rate': 0.09457736727811783, 'subsample': 0.7860455629719446}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:36:04,866] Trial 47 finished with value: 0.8969469036081821 and parameters: {'n_estimators': 354, 'max_depth': 8, 'learning_rate': 0.08067214364278961, 'subsample': 0.7443743658798874}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:39:20,493] Trial 48 finished with value: 0.8954326416260562 and parameters: {'n_estimators': 384, 'max_depth': 6, 'learning_rate': 0.05322576574366585, 'subsample': 0.7658758409904844}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:40:36,104] Trial 49 finished with value: 0.8921714121975157 and parameters: {'n_estimators': 89, 'max_depth': 9, 'learning_rate': 0.09990796906274538, 'subsample': 0.7206093548880784}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:43:57,767] Trial 50 finished with value: 0.895073193384543 and parameters: {'n_estimators': 334, 'max_depth': 7, 'learning_rate': 0.04909097292051413, 'subsample': 0.953078875744169}. Best is trial 33 with value: 0.8973770242385077.\n",
      "[I 2024-01-02 19:50:17,576] Trial 51 finished with value: 0.8974075637606056 and parameters: {'n_estimators': 396, 'max_depth': 8, 'learning_rate': 0.07564040292976085, 'subsample': 0.7780320680145622}. Best is trial 51 with value: 0.8974075637606056.\n",
      "[I 2024-01-02 19:57:40,182] Trial 52 finished with value: 0.8973551621081421 and parameters: {'n_estimators': 386, 'max_depth': 9, 'learning_rate': 0.06216309301535705, 'subsample': 0.7709783461790619}. Best is trial 51 with value: 0.8974075637606056.\n",
      "[I 2024-01-02 20:07:53,228] Trial 53 finished with value: 0.8973377522799364 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.06118053715011491, 'subsample': 0.7755036157306117}. Best is trial 51 with value: 0.8974075637606056.\n",
      "[I 2024-01-02 20:11:44,671] Trial 54 finished with value: 0.8975221847134165 and parameters: {'n_estimators': 388, 'max_depth': 9, 'learning_rate': 0.06136163259560551, 'subsample': 0.7752559466769434}. Best is trial 54 with value: 0.8975221847134165.\n",
      "[I 2024-01-02 20:15:29,131] Trial 55 finished with value: 0.8971582074616011 and parameters: {'n_estimators': 387, 'max_depth': 9, 'learning_rate': 0.06671339350655534, 'subsample': 0.7635027221705998}. Best is trial 54 with value: 0.8975221847134165.\n",
      "[I 2024-01-02 20:19:02,249] Trial 56 finished with value: 0.8973511618393143 and parameters: {'n_estimators': 370, 'max_depth': 9, 'learning_rate': 0.05582502857091449, 'subsample': 0.789311179628824}. Best is trial 54 with value: 0.8975221847134165.\n",
      "[I 2024-01-02 20:22:45,226] Trial 57 finished with value: 0.8971525688575325 and parameters: {'n_estimators': 390, 'max_depth': 9, 'learning_rate': 0.061686992509589575, 'subsample': 0.7416996774250397}. Best is trial 54 with value: 0.8975221847134165.\n",
      "[I 2024-01-02 20:25:04,594] Trial 58 finished with value: 0.8942037024776862 and parameters: {'n_estimators': 240, 'max_depth': 9, 'learning_rate': 0.04047783029665404, 'subsample': 0.8118656838749292}. Best is trial 54 with value: 0.8975221847134165.\n",
      "[I 2024-01-02 20:25:56,193] Trial 59 finished with value: 0.8875158087536302 and parameters: {'n_estimators': 209, 'max_depth': 4, 'learning_rate': 0.06844717775618789, 'subsample': 0.7747620275735021}. Best is trial 54 with value: 0.8975221847134165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data: 0.8836199680814258\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Feature Engineering (example: BMI)\n",
    "train['bmi'] = train['weight(kg)'] / (train['height(cm)'] / 100) ** 2\n",
    "test['bmi'] = test['weight(kg)'] / (test['height(cm)'] / 100) ** 2\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking', 'id'])  # Exclude the target variable and 'id'\n",
    "y_train = train['smoking']\n",
    "X_test = test.drop(columns=['id'])  # Assuming 'id' is not a feature\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    for train_index, val_index in kf.split(X_train_balanced, y_train_balanced):\n",
    "        X_train_kf, X_val_kf = X_train_balanced[train_index], X_train_balanced[val_index]\n",
    "        y_train_kf, y_val_kf = y_train_balanced[train_index], y_train_balanced[val_index]\n",
    "\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "        y_pred = model.predict_proba(X_val_kf)[:,1]\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_kf, y_pred))\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "# Optuna optimization with 10 trials\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=60)\n",
    "\n",
    "# Best model\n",
    "best_params = study.best_params\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Accuracy on the training data\n",
    "y_pred_train = model.predict(X_train_balanced)\n",
    "accuracy_train = accuracy_score(y_train_balanced, y_pred_train)\n",
    "print(f\"Accuracy on Training Data: {accuracy_train}\")\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred_proba_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking_probability'] = y_pred_proba_test\n",
    "submission.to_csv('XGB_Optuna_Enhanced_Submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets try to merge the Optuna with the best version yet XGB2.2_Enhanced_Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best XGB version \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Feature Engineering (example: BMI)\n",
    "train['bmi'] = train['weight(kg)'] / (train['height(cm)'] / 100) ** 2\n",
    "test['bmi'] = test['weight(kg)'] / (test['height(cm)'] / 100) ** 2\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking', 'id'])  # Exclude the target variable and 'id'\n",
    "y_train = train['smoking']\n",
    "X_test = test.drop(columns=['id'])  # Assuming 'id' is not a feature\n",
    "\n",
    "# Ensure X_train and X_test have the same columns\n",
    "assert X_train.columns.equals(X_test.columns), \"Columns of X_train and X_test do not match\"\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Model training using XGBoost Classifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Feature Selection\n",
    "selector = RFECV(xgb_model, step=1, cv=3)\n",
    "X_train_selected = selector.fit_transform(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_dist = {\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=50, scoring='roc_auc', cv=3, random_state=42)\n",
    "random_search.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "# Best model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred_train = cross_val_predict(best_xgb_model, X_train_selected, y_train_balanced, cv=3)\n",
    "accuracy = accuracy_score(y_train_balanced, y_pred_train)\n",
    "precision = precision_score(y_train_balanced, y_pred_train)\n",
    "recall = recall_score(y_train_balanced, y_pred_train)\n",
    "f1 = f1_score(y_train_balanced, y_pred_train)\n",
    "roc_auc = roc_auc_score(y_train_balanced, y_pred_train)\n",
    "\n",
    "# Predictions on test data\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "y_pred_proba_test = best_xgb_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking_probability'] = y_pred_proba_test\n",
    "submission.to_csv('XGB2.2_Enhanced_Submission.csv', index=False)\n",
    "\n",
    "\n",
    "# version 2 of 0.87 but runtime over \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best result yet (of the merge) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Feature Engineering (example: BMI)\n",
    "train['bmi'] = train['weight(kg)'] / (train['height(cm)'] / 100) ** 2\n",
    "test['bmi'] = test['weight(kg)'] / (test['height(cm)'] / 100) ** 2\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking', 'id'])  # Exclude the target variable and 'id'\n",
    "y_train = train['smoking']\n",
    "X_test = test.drop(columns=['id'])  # Assuming 'id' is not a feature\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    for train_index, val_index in kf.split(X_train_balanced, y_train_balanced):\n",
    "        X_train_kf, X_val_kf = X_train_balanced[train_index], X_train_balanced[val_index]\n",
    "        y_train_kf, y_val_kf = y_train_balanced[train_index], y_train_balanced[val_index]\n",
    "\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "        y_pred = model.predict_proba(X_val_kf)[:,1]\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_kf, y_pred))\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "# Optuna optimization with 10 trials\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=60)\n",
    "\n",
    "# Best model\n",
    "best_params = study.best_params\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Accuracy on the training data\n",
    "y_pred_train = model.predict(X_train_balanced)\n",
    "accuracy_train = accuracy_score(y_train_balanced, y_pred_train)\n",
    "print(f\"Accuracy on Training Data: {accuracy_train}\")\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred_proba_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking_probability'] = y_pred_proba_test\n",
    "submission.to_csv('XGB_Optuna_Enhanced_Submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this only the Best Version (A7ssen score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = train.drop(columns=['smoking', 'id'])\n",
    "y_train = train['smoking']\n",
    "X_test = test.drop(columns=['id'])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Optuna objective\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    for train_index, val_index in kf.split(X_train_balanced, y_train_balanced):\n",
    "        X_train_kf, X_val_kf = X_train_balanced[train_index], X_train_balanced[val_index]\n",
    "        y_train_kf, y_val_kf = y_train_balanced[train_index], y_train_balanced[val_index]\n",
    "\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "        y_pred = model.predict_proba(X_val_kf)[:,1]\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_kf, y_pred))\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "# Optuna optimization with 10 merat\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Best model\n",
    "best_params = study.best_params\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred_proba_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file for test data\n",
    "submission = test[['id']].copy()\n",
    "submission['smoking_probability'] = y_pred_proba_test\n",
    "submission.to_csv('XGB_Optuna_Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 21), (5, 19), (10, 24), (4, 17), (3, 16), (11, 25), (14, 24), (6, 22), (10, 21), (12, 21)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\houss\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "x = [4,5,10,4,3,11,14,6,10,12]\n",
    "y = [21,19,24,17,16,25,24,22,21,21]\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n",
    "data = list(zip(x,y))\n",
    "print(data)\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(data)\n",
    "\n",
    "plt.scatter(x,y, c=kmeans.labels_)\n",
    "plt.show()\n",
    "\n",
    "new_x = 6\n",
    "new_y = 20\n",
    "new_data = [(new_x, new_y)]\n",
    "prediction = kmeans.predict(new_data)\n",
    "print(prediction)\n",
    "\n",
    "plt.scatter(x+[new_x], y+[new_y], color='r')\n",
    "plt.text(x=new_x-1.7, y=new_y-0.7, s=f\"new point, class: {prediction[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(False, 20.3, 'new point, class: 1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "x = [4, 5, 10, 4, 3, 11, 14, 8, 10, 12]\n",
    "y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\n",
    "classes = [0,0,1,0,0,1,1,0,1,1]\n",
    "\n",
    "plt.scatter(x, y, c=classes)\n",
    "plt.show()\n",
    "\n",
    "data = list(zip(x, y))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(data, classes)\n",
    "\n",
    "new_x = 8\n",
    "new_y = 21\n",
    "new_point = [[new_x, new_y]]\n",
    "prediction = knn.predict(new_point)\n",
    "plt.scatter(x + [new_x], y + [new_y], c=classes + [prediction[0]])\n",
    "plt.text(x==new_x-1.7,y=new_y-0.7,s=f\"new point, class: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "   support         itemsets\n",
      "0    0.750           (milk)\n",
      "1    0.750          (bread)\n",
      "2    0.625         (butter)\n",
      "3    0.500            (jam)\n",
      "4    0.500    (milk, bread)\n",
      "5    0.500  (butter, bread)\n",
      "6    0.375   (butter, milk)\n",
      "7    0.375     (jam, bread)\n",
      "8    0.375      (milk, jam)\n",
      "\n",
      "Association Rules:\n",
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0    (butter)     (bread)               0.625                0.75    0.500   \n",
      "1       (jam)     (bread)               0.500                0.75    0.375   \n",
      "2       (jam)      (milk)               0.500                0.75    0.375   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0        0.80  1.066667   0.03125        1.25       0.166667  \n",
      "1        0.75  1.000000   0.00000        1.00       0.000000  \n",
      "2        0.75  1.000000   0.00000        1.00       0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Sample transaction dataset\n",
    "transactions = [\n",
    "    ['bread', 'milk', 'butter'],\n",
    "    ['bread', 'milk'],\n",
    "    ['bread', 'butter'],\n",
    "    ['milk', 'butter'],\n",
    "    ['bread', 'milk', 'butter', 'jam'],\n",
    "    ['bread', 'milk', 'jam'],\n",
    "    ['bread', 'butter', 'jam'],\n",
    "    ['milk', 'jam']\n",
    "]\n",
    "\n",
    "# Convert the transaction dataset into a one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Find frequent itemsets using FP-Growth\n",
    "frequent_itemsets = fpgrowth(df, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Select only confidence and support columns\n",
    "selected_rules = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
    "\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "print(\"\\nAssociation Rules (Selected Columns):\")\n",
    "print(selected_rules)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
